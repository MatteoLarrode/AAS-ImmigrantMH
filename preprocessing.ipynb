{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Project and Preprocess data\n",
    "\n",
    "After moving in the terminal to the current directory, I first created a virtual environment using Python 3.11 with `python3.11 -m venv .venv`. \n",
    "\n",
    "I then activated it using `source .venv/bin/activate`.\n",
    "\n",
    "Finally, I run `python3 -m pip install -r requirements.txt` to install all requirements. I keep the `requirements.txt` file up to date with all the packages I use during the course of the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/ Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.visualisations_helpers import *\n",
    "from utils.cleaning_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/hzh5vjhs64sfqz3fgg0md4x80000gn/T/ipykernel_68570/1266792573.py:6: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  indresp[i] = pd.read_stata(f'data/ukhls/{wave}_indresp.dta', convert_categoricals=False)\n"
     ]
    }
   ],
   "source": [
    "waves = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm']\n",
    "indresp = {}\n",
    "\n",
    "for i, wave in enumerate(waves, start=1):\n",
    "    try:\n",
    "        indresp[i] = pd.read_stata(f'data/ukhls/{wave}_indresp.dta', convert_categoricals=False)\n",
    "    except FileNotFoundError:\n",
    "        print(f'Error: {wave}_indresp.dta not found.')\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f'Error loading {wave}_indresp.dta: {e}')\n",
    "        continue\n",
    "\n",
    "# Load cross-wave variables\n",
    "xwave = pd.read_stata('data/ukhls/xwavedat.dta', convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II/ Filtering columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_of_interest_base = [\n",
    "    'pidp', 'hidp', 'month', 'istrtdaty', 'indscui_xw',\n",
    "    'sf12mcs_dv', 'discrim', 'jbstat', 'ff_oprlg', 'age_dv', \n",
    "    'hiqual_dv', 'mreason1', 'mreason2', 'mreason3', 'mreason4', 'mreason5',\n",
    "    'mreason6', 'mreason7', 'mreason97', 'mlstat', 'gor_dv'\n",
    "]\n",
    "\n",
    "variables_of_interest_cross_wave = [\n",
    "    'pidp', 'memorig', 'psu', 'strata', 'sex', 'birthy', 'ethn_dv',\n",
    "    'bornuk_dv', 'generation', 'yr2uk4'\n",
    "]\n",
    "\n",
    "# Dictionary to store the filtered dataset\n",
    "filtered_indresp = {}\n",
    "\n",
    "# Filter each dataset in indresp to include only the variables of interest\n",
    "# Add a column to each wave indicating the presence of that wave\n",
    "for i, wave in enumerate(waves, start=1):\n",
    "    variables_of_interest = ['pidp'] + [f'{wave}_{var}' for var in variables_of_interest_base if var != 'pidp']\n",
    "    if i in indresp:\n",
    "        filtered_df = indresp[i][[var for var in variables_of_interest if var in indresp[i].columns]].copy()  # Use .copy() to ensure it's a new DataFrame\n",
    "        filtered_df[f'{wave}_present'] = 1  # Safely assign new column\n",
    "        filtered_indresp[i] = filtered_df\n",
    "\n",
    "# Filter xwave to include only the variables of interest\n",
    "filtered_xwave = xwave[[var for var in variables_of_interest_cross_wave if var in xwave.columns]].copy()  # Use .copy() here as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III/ Merging and reshaping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I can merge all waves on the pidp column (keep all columns and fill missing values with NaN)\n",
    "from functools import reduce\n",
    "\n",
    "# Merge all waves\n",
    "merged_indresp = reduce(lambda left, right: pd.merge(left, right, on='pidp', how='outer'), filtered_indresp.values())\n",
    "\n",
    "# Fill NaN values in the presence columns with 0\n",
    "for wave in waves:\n",
    "    merged_indresp[f'{wave}_present'] = merged_indresp[f'{wave}_present'].fillna(0)\n",
    "\n",
    "# Merge cross-wave variables\n",
    "merged_indresp = pd.merge(merged_indresp, filtered_xwave, on='pidp', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform wide dataframe to long (tidy)\n",
    "# Identify columns to melt (contain underscores but are not in id_vars)\n",
    "value_vars = [col for col in merged_indresp.columns if col not in variables_of_interest_cross_wave and '_' in col]\n",
    "\n",
    "# Melt the dataframe\n",
    "df_long = pd.melt(merged_indresp, \n",
    "                  id_vars = variables_of_interest_cross_wave, \n",
    "                  value_vars = value_vars, \n",
    "                  var_name='wave_variable', value_name='value')\n",
    "\n",
    "# Extract the first component as 'wave' and the rest as 'variable'\n",
    "df_long['wave'] = df_long['wave_variable'].str.extract(r'([a-z])_')[0]\n",
    "df_long['variable'] = df_long['wave_variable'].str.extract(r'^[a-z]_(.*)')[0]\n",
    "\n",
    "# Pivot the dataframe to keep variables as columns\n",
    "df_long = df_long.pivot_table(index=variables_of_interest_cross_wave + ['wave'], \n",
    "                              columns='variable', \n",
    "                              values='value', \n",
    "                              aggfunc='first').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV/ Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:06<00:00,  5.22it/s]\n"
     ]
    }
   ],
   "source": [
    "final_df = (df_long\n",
    "            .copy()\n",
    "            .pipe(recode_negative_as_missing)\n",
    "            .pipe(recode_binary_sex_column)\n",
    "            .pipe(recode_binary_variables, ['bornuk_dv', 'discrim', 'ff_oprlg'])\n",
    "            .pipe(recode_ethnicity)\n",
    "            .pipe(recode_migrant_generation)\n",
    "            .pipe(recode_education)\n",
    "            .pipe(recode_labour_force_status)\n",
    "            .pipe(recode_region))\n",
    "\n",
    "\n",
    "\n",
    "# Drop columns which were recoded\n",
    "final_df = final_df.drop(columns=['ethn_dv', 'generation', 'hiqual_dv', 'jbstat', 'gor_dv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# === Create new variables ===\n",
    "# ============================\n",
    "# 1/ TIME SINCE ARRIVAL IN THE UK\n",
    "# (Time of interview (istrtdaty) - year of arrival in the UK (yr2uk4))\n",
    "# Set 'yr2uk4' to NaN for UK-born people\n",
    "final_df.loc[final_df['bornuk_dv'] == 1, 'yr2uk4'] = np.nan\n",
    "\n",
    "# Calculate years since arrival as an integer\n",
    "final_df['years_since_arrival'] = (final_df['istrtdaty'] - final_df['yr2uk4']).astype('Int64')\n",
    "\n",
    "# Set 'years_since_arrival' to NA where either 'istrtdaty' or 'yr2uk4' is NaN\n",
    "final_df.loc[final_df[['istrtdaty', 'yr2uk4']].isna().any(axis=1), 'years_since_arrival'] = np.nan\n",
    "\n",
    "# Categorical variable for years since arrival\n",
    "bins = [0, 4, 9, 14, 19, np.inf]\n",
    "labels = ['0-4', '5-9', '10-14', '15-19', '20+']\n",
    "final_df['years_since_arrival_cat'] = pd.cut(final_df['years_since_arrival'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Binary variable for years since arrival (10+ years)\n",
    "final_df['years_since_arrival_binary'] = final_df['years_since_arrival'].apply(lambda x: 1 if pd.notna(x) and x > 10 else (0 if pd.notna(x) else pd.NA))\n",
    "\n",
    "# --------------------------------\n",
    "# 2/ IMMIGRANT VARIABLES \n",
    "# Binary (bornuk_dv == 0)\n",
    "final_df = create_immigrant_variable(final_df)\n",
    "\n",
    "# Categorical\n",
    "final_df['imm_group'] = final_df['bornuk_dv'].map({1: 'UK-born', 0: 'Immigrants'})\n",
    "\n",
    "# --------------------------------\n",
    "# 3/ UNEMPLOYMENT\n",
    "final_df['unemployed'] = final_df['jbstat_recoded'].apply(lambda x: 1 if x == 'Unemployed' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4/ REASON FOR MIGRATION\n",
    "# !! only meaningful for immigrants, so requires the intervention of an indicator variable !!\n",
    "# Note: this is an exception to the general rule that terms should not be included as interactions without a main effect term\n",
    "\n",
    "# Mapping of reasons to categories\n",
    "mreason_labels = {\n",
    "    'mreason1': 'Work/Education',\n",
    "    'mreason5': 'Work/Education',\n",
    "    'mreason2': 'Family',\n",
    "    'mreason3': 'Family',\n",
    "    'mreason4': 'Family',\n",
    "    'mreason6': 'Political safety',\n",
    "    'mreason7': 'Wanted to live in UK',\n",
    "    'mreason97': 'Other',\n",
    "}\n",
    "\n",
    "# Ensure the necessary columns are in the DataFrame\n",
    "required_columns = list(mreason_labels.keys())\n",
    "missing_columns = [col for col in required_columns if col not in final_df.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing required columns in final_df: {missing_columns}\")\n",
    "\n",
    "# Convert the mapping dictionary to a DataFrame\n",
    "mreason_mapping = pd.DataFrame(\n",
    "    list(mreason_labels.items()), columns=['Variable', 'Category']\n",
    ")\n",
    "\n",
    "# Reshape the DataFrame to long format for processing reasons\n",
    "melted = (\n",
    "    final_df[required_columns]\n",
    "    .reset_index()\n",
    "    .melt(id_vars='index', var_name='Variable', value_name='Value')\n",
    "    .query('Value == 1')  # Filter only selected reasons\n",
    "    .merge(mreason_mapping, on='Variable', how='left')  # Map reasons to categories\n",
    ")\n",
    "\n",
    "# Resolve multiple reasons by selecting the first category per respondent\n",
    "mreason_by_index = (\n",
    "    melted.groupby('index')['Category']\n",
    "    .first()  # Use the first match if multiple reasons exist\n",
    "    .reindex(final_df.index, fill_value='Unknown')  # Fill 'Unknown' for respondents with no reason\n",
    ")\n",
    "\n",
    "# Add the 'mreason' column to the original DataFrame\n",
    "final_df['mreason'] = mreason_by_index\n",
    "\n",
    "# Assign 'N/A' to UK-born individuals\n",
    "final_df.loc[final_df['imm_group'] == 'Domestic-born', 'mreason'] = 'N/A'\n",
    "\n",
    "# Drop the original migration reason columns\n",
    "final_df = final_df.drop(columns=required_columns)\n",
    "\n",
    "# Ensure final column updates are meaningful\n",
    "final_df['mreason'] = final_df['mreason'].fillna('Unknown')  # Handle any unexpected missing values\n",
    "\n",
    "# Ensure 'mreason' is a categorical variable with 'Unknown' as the reference category\n",
    "categories_order = ['Unknown', 'Work/Education', 'Family', 'Political safety', 'Wanted to live in UK', 'Other', 'N/A']\n",
    "final_df['mreason'] = pd.Categorical(\n",
    "    final_df['mreason'],\n",
    "    categories=categories_order,\n",
    "    ordered=True  # Makes it an ordered categorical variable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only the discrimination variable and related columns\n",
    "discrimination_df = final_df[['pidp', 'discrim']].dropna(subset=['discrim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V/ Choice of wave(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wave\n",
      "g    3605\n",
      "Name: count, dtype: int64\n",
      "['Work/Education', 'Family', 'Wanted to live in UK', 'Other', 'Political safety']\n",
      "Categories (7, object): ['Unknown' < 'Work/Education' < 'Family' < 'Political safety' < 'Wanted to live in UK' < 'Other' < 'N/A']\n"
     ]
    }
   ],
   "source": [
    "# Now that all variables of interest have been filtered and cleaned\n",
    "# I can choose which wave(s) to use for the analysis: this will depend on missing values \n",
    "\n",
    "# Initial condition: Filter final_df to include only rows with sf12mcs_dv, immigrant group and ethnicity\n",
    "data = final_df.dropna(subset=['sf12mcs_dv', 'imm_group', 'ethn_dv_recoded'])\n",
    "\n",
    "# Which waves include known data on reasons for migration\n",
    "# Filter dataframe to include only rows with reasons for migration different than 'Unknown' and 'N/A'\n",
    "known_migration_df = data[(data['mreason'] != 'Unknown') & (data['mreason'] != 'N/A')]\n",
    "print(known_migration_df['wave'].value_counts())\n",
    "print(known_migration_df['mreason'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only wave which includes observations with both mental health of immigrants and their reason to migrate is Wave 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI/ Creation of the analysis datasets (wave 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# === Create final dataset ===\n",
    "# ============================\n",
    "# Cross-sectional analysis: wave 7\n",
    "df_wave_7 = (final_df\n",
    "             .query(\"wave == 'g' and present == 1\")\n",
    "             .dropna(axis=1, how='all')\n",
    "             .dropna(subset=['bornuk_dv', 'sf12mcs_dv', 'sex', 'ethn_dv_recoded', 'hiqual_dv_recoded', 'unemployed', 'gor_dv_recoded'])\n",
    "             .query(\"16 <= age_dv <= 80\")\n",
    "             .query(\"(imm_group == 'Immigrants') or generation_recoded != '2nd generation'\")\n",
    "             .merge(discrimination_df, on='pidp', how='left')\n",
    "            )\n",
    "\n",
    "# Pickle the final dataset\n",
    "df_wave_7.to_pickle('data/wave7_data.pkl')\n",
    "\n",
    "# Save the final dataset to a CSV file (does not preserve the categorical data types)\n",
    "df_wave_7.to_csv('data/wave7_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# === Part 1 Dataset ===\n",
    "# ======================\n",
    "# Remove immigrants who have lived in the UK for more than 15 years\n",
    "df_wave_7_part1 = df_wave_7.query(\"imm_group == 'UK-born' or years_since_arrival_binary == 0\")\n",
    "\n",
    "# Pickle the final dataset\n",
    "df_wave_7_part1.to_pickle('data/wave7_data_part1.pkl')\n",
    "\n",
    "# Save the final dataset to a CSV file (does not preserve the categorical data types)\n",
    "df_wave_7_part1.to_csv('data/wave7_data_part1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# === Part 2 Dataset ===\n",
    "# ======================\n",
    "# Reduce sample to only immigrants\n",
    "df_wave_7_part2 = df_wave_7[df_wave_7['imm_group'] == 'Immigrants']\n",
    "\n",
    "# Remove immigrants without years since arrival\n",
    "df_wave_7_part2 = df_wave_7_part2.dropna(subset=['years_since_arrival'])\n",
    "\n",
    "# Pickle the final dataset\n",
    "df_wave_7_part2.to_pickle('data/wave7_data_part2.pkl')\n",
    "\n",
    "# Save the final dataset to a CSV file (does not preserve the categorical data types)\n",
    "df_wave_7_part2.to_csv('data/wave7_data_part2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
